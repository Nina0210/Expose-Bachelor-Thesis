\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}       
\usepackage[polish,english]{babel} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}

\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{natbib}
\usepackage{titlesec}
%\usepackage{multicol}

% Title Formatting
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}

\title{Memory Efficient Efficient PageRank on Apache Spark}
\author{Nina Michalek\\TU Berlin, DOS}
\date{April 7, 2025}

\begin{document}

\maketitle

%\begin{multicols}{2}

\section{Introduction}
 Graphs are widely used to represent relationships between different entities for applications such as social networks and website connections \cite{zhang_distributed_2021}. 
To analyze these, numerous graph algorithms have been proposed. Among the most influential is PageRank, an iterative algorithm introduced by Google to determine website importance. PageRank has become a common component within specialized graph processing frameworks. These systems are designed to efficiently execute iterative algorithms, making graph analytics more practical. An example of such a system is GraphX \cite{xin_graphx_2013}, built upon Apache Spark \cite{xin_graphx_2013}. Spark itself is a popular open source distributed dataflow system that enables large-scale data processing \cite{shanahan_large_2015}. GraphX acts as a graph processing framework that aims to bridge the gap between system-level optimisations in specialised graph engines and the flexible dataflow operations available in general-purpose systems \cite{jin_software_2022}. However, recent research has addressed the huge memory overhead in GraphX's PageRank algorithm due to the data representation. It proposes approximate computation to reduce memory consumption \cite{wu_efficient_2024}. 
 

\section{Problem Description}
The rapid expansion of the World Wide Web during the late 1990's presented a significant challenge for the information retrieval cite. With the launch of Google in 1998 cite, PageRank was introduced as a core component of the search engine cite. PageRank is an algorithm that is ranking web pages by measuring their relative importance based on the graph of the web \cite{page_pagerank_1999}. The node of the graph are the web pages while the edges represent links. An outedge is a link on a website and an inedge is a backlink \cite{page_pagerank_1999}. A page is considered important if it has inedges from important pages. The value of a web page is calculated recursively based on the values of all pages linking to it. Linking pages pass a fraction of its own value, proportional to its number of outedges, to the target page. This is an iterative calculation with a damping factor that converges to a stable probability distribution \cite{page_pagerank_1999}. 
Today PageRank is used, not only in search engines, but in a wide range of applications such as social networks \cite{wu_efficient_2024}. The latter utilizes PageRank to identify influential users, rank content in feeds and recommend people \cite{weng_twitterrank_2010}. Despite its wide applicability, a fundamental challenge lies in the graph representation \cite{liu_fast_2015}. Typically, graphs are represented in matrices, which in the worst case require up to $O(n^2)$ of memory, where $n$ is the number of web pages \cite{wu_efficient_2024}. The transition matrix, containing the probabilities of moving from one web page to another in a single step, presents a significant memory challenge as graph sizes grow. 

%The transition matrix stores the probabilities of moving from one web page to another in one single step. It becomes a significant memory bottleneck as the size of the graph increases, making it impractical to directly store or process the entire graph. GraphX's PageRank comes with a static and a dynamic version \cite{xin_graphx_2013}. Static PageRank runs for a fixed number of iterations, while dynamic PageRank runs until the ranks converge \cite{xin_graphx_2013}. Both implementations use power iteration to update values \cite{xin_graphx_2013}, which requires many passes over the graph, resulting in expensive matrix operations. % A fundamental challenge lies in the graph representation itself \cite{liu_fast_2015}. Typically, graphs are represented in matrices, which in the worst case require up to $O(n^2)$ of memory \cite{wu_efficient_2024}. The transition matrix becomes a significant memory bottleneck as the size of the graph increases, making it impractical to directly store or process the entire graph. Therefore, efficient models that avoid full matrix construction and instead rely on approximations are needed \cite{liu_fast_2015}.
%However, research shows that most implementations of the algorithm are inefficient when applied to large scale graphs due to a huge computational overhead \cite{wu_efficient_2024}\cite{jayaram_dynamic_2024}\cite{yang_efficient_2024}. 



\section{State of the Art}
Today there are numerous approximate PageRank implementations that address the computational overhead in the original implementation  \cite{wu_efficient_2024}. They use different approaches to achieve a better performance. Some of them use iteration algorithms that work by updating the ranks step by step until the values stop changing much \cite{xie_parameterized_2023}\cite{anikin_efficient_2022}. Although there is a threshold it takes a significant amount of time on large scale graphs to converge \cite{wu_efficient_2024}. Monte Carlo based algorithms estimate node importance by simulating random walks over the graph \cite{avrachenkov_monte_2007}. For large graphs and high accuracy the algorithm requires a lot of these walks. Another approach only takes samples instead of the whole graph \cite{wu_approxrank_2009}\cite{bar-yossef_local_2008}. Sampling algorithms estimate the importance of a node by it's local area. Although this approach achieves a better runtime than other algorithms, the memory consumption is similar. Finally, matrix approximation-based PageRank algorithms reduce the rank of the matrix to simplify computations \cite{liu_fast_2015}. This results in faster computing time but usually the construction of low-rank matrices is high . Recent research addresses the problem and further optimizes the performance and accuracy by sampling substructures in the graph that are informative about node importance. It further simplifies the computation by constructing a low-rank approximation of the PageRank matrix using representative columns and rows \cite{wu_efficient_2024}. \\Apache Spark introduced GraphX in 2014 which features a static and dynamic implementation of the PageRank algorithm \cite{xin_graphx_2013}. While GraphX was a huge step forward in distributed graph processing \cite{gonzalez_graphx_2014-1}, it has several limitations. Especially, memory limitations arising from the use of power iterations \cite{page_pagerank_1999} and the use of RDD-based message passing become significant performance bottlenecks \cite{xin_graphx_2014}\cite{xin_graphx_2013}.
 

\section{Approach}
The novel approach of the thesis will be to implement an approximate PageRank algorithm on Apache Spark. As the existing GraphX library is not sufficient for large-scale graphs but poses a practical framework for many users, the new implementation should address the computational overhead and introduce an approach that focuses on low memory consumption. 
The result of recent research shows that there are several algorithms that perform better than the original PageRank algorithm \cite{wu_efficient_2024}, but have not been implemented in a general use framework. The main goal of the thesis is to implement a state of the art method on the basis of Apache Spark that requires less memory than GraphX's PageRank implementation. 

One idea is the $T^2$-Approx algorithm \cite{wu_efficient_2024}. It addresses issues in existing algorithms and generalizes other matrix approximation-based PageRank algorithms. The algorithm uses a modified low-rank approximation of $T^2$, where $T$ is the transition matrix of the graph. It directly approximates $T^2$ by using two smaller matrices $X$ and $Y$ instead of approximating $T$ and then computing $T^k$. It then estimates $T^k$ by iteratively computing powers of the small matrix. The approach relies on low-rank approximation, leveraging only a subset of rows and columns, which significantly reduces memory consumption. Since the PageRank algorithm tolerates approximate values, this method is an effective way to reduce computational overhead.

Another algorithm that implements a more efficient version of PageRank is the CUR-Trans algorithm \cite{wu_efficient_2024}. It is based on a modified CUR decomposition, which is applied to the transition matrix. The algorithm splits the large matrix $T$ into three small matrices $C, \tilde{U}$ and $R$, where $C$ and $R$ are sampled columns and rows and $\tilde{U}$ is a low-rank approximation of the intersection of $C$ and $R$. A new, significantly smaller Graph is then constructed based on the matrices. The PageRank algorithm is running on the reduced graph and the results are mapped back to the initial graph.

After the implementation of a state of the art approach, the setup will be evaluated. As this thesis aims to address the inefficiencies in GraphX's PageRank implementation, the primary evaluation metric will be the memory usage. A tradeoff in accuracy is considered acceptable. The original GraphX's PageRank algorithm will serve as a baseline for comparison. 



\section{References}
\bibliographystyle{plain}  % Choose a citation format
\bibliography{references}   % Link to your BibTeX file

%\end{multicols}

\end{document}
